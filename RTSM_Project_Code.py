# -*- coding: utf-8 -*-
"""RTSM - Term Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hvxGfTAlyAvIOgInb131-viDGnjsjLFd

**Importing relevant libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import seaborn as sns
import random
import math
from scipy import stats
from tqdm import tqdm
from pandas.plotting import scatter_matrix

from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import auc
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, roc_auc_score, roc_curve, recall_score

"""**Loading the dataset**"""

df = pd.read_csv('SpotifyAudioFeaturesNov2018.csv')
df.drop_duplicates(subset=['track_id'], inplace=True)
df.to_csv('cleaned_data.csv', index=False)
df.info()

"""**Analysis of each feature**"""

# Select numerical columns
numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns

# Calculate the mean and variances of each numerical column
column_means = df[numerical_columns].mean(axis=0)
column_variances = df[numerical_columns].var(axis=0)

# Create a DataFrame to store the results
results_df = pd.DataFrame({
    'Column Name': numerical_columns,
    'Mean': column_means,
    'Standard Deviation': column_variances**(0.5)
})

# Display the results side by side
print(results_df.to_string())

"""**Step-0: Exploratory Data Analysis**

Distribution of Popularity Scores
"""

sns.histplot(data=df['popularity']/100, bins=50, color='lightgreen', kde=True, stat='density')
sns.kdeplot(data=df['popularity']/100, color='green', linewidth=2)

plt.xlim(-0.05, 1.05)
plt.grid(axis='x')
plt.grid(axis='y')

plt.title('Distribution of Popularity Scores')
plt.xlabel('Popularity')
plt.ylabel('Density')

plt.show()

"""Scatter Plots of various features"""

# Define the features you want to plot
features = ["danceability", "energy", "instrumentalness", "loudness", "valence", "popularity"]

# Initialize the subplot grid
fig, axes = plt.subplots(6, 6, figsize=(12, 10))

# Iterate through each pair of features and create a scatter plot
for i in range(6):
    for j in range(6):
        if(i==j):
          feature1 = features[i]
          ax = axes[j][i]
          sns.kdeplot(df[feature1])
          ax.set_xlabel(feature1)
          ax.set_ylabel(feature1)
        else:
          feature1 = features[i]
          feature2 = features[j]
          ax = axes[j][i]
          ax.scatter(df[feature1], df[feature2], alpha=0.2)
          ax.set_xlabel(feature1)
          ax.set_ylabel(feature2)

# Adjust the spacing between subplots
plt.tight_layout()

# Show the plot
plt.show()

def plot_pairplot(df, rows, cutoff):
    df = df.copy()
    df['pop_bin'] = np.where(df['popularity'] > cutoff, "Popular", "Not_Popular")
    cols_for_pp = ['danceability', 'energy', 'instrumentalness',
       'loudness','valence', 'popularity', 'pop_bin']
    sns.pairplot(df.loc[:rows, cols_for_pp], hue='pop_bin', size=2)
    plt.show()

plot_pairplot(df, rows = 116000, cutoff = 55)

"""Violin Plots to check similarity between mean of independent variables"""

cutoff = 55
sns.set(style="whitegrid")
df['pop_bin'] = np.where(df['popularity'] > cutoff, "Popular", "Not_Popular")

fig, ax = plt.subplots(1, 3, sharey=True, figsize=(12,4))
fig.suptitle('Distributions of Selected Features at Popularity Score Cutoff of 55')

sns.violinplot(x=df['pop_bin'], y=df['danceability'], ax=ax[0], data=df, hue='pop_bin')
sns.violinplot(x=df['pop_bin'], y=df['valence'], ax=ax[1], data=df, hue='pop_bin')
sns.violinplot(x=df['pop_bin'], y=df['acousticness'], ax=ax[2], data=df, hue='pop_bin')

plt.show()

sns.set(style="whitegrid")

fig, ax = plt.subplots(1, 3, sharey=True, figsize=(12,4))
fig.suptitle('Distributions of Selected Features at Popularity Score Cutoff of 55')

sns.violinplot(x=df['pop_bin'], y=df['energy'], ax=ax[0], data=df, hue='pop_bin')
sns.violinplot(x=df['pop_bin'], y=df['instrumentalness'], ax=ax[1], data=df, hue='pop_bin')
sns.violinplot(x=df['pop_bin'], y=df['liveness'], ax=ax[2], data=df, hue='pop_bin')

plt.show()

numerical_features = df.select_dtypes(include=["int64", "float64"])
corr = numerical_features.corr()

# Create a heatmap
plt.figure(figsize=(11,9))
sns.heatmap(corr, annot=True, cmap="coolwarm")

# Add a title
plt.title("Correlation Matrix of Features")

# Show the plot
plt.show()

"""Scatter plots of few features v/s popularity"""

fig, axes = plt.subplots(1, 3, figsize=(18, 8))
axes[0].scatter(df['danceability'], df['popularity'], alpha=0.4)
axes[1].scatter(df['key'], df['popularity'], alpha=0.4)
axes[2].scatter(df['acousticness'], df['popularity'], alpha=0.4)
axes[0].set_ylabel("popularity")
axes[0].set_xlabel("danceability")
axes[1].set_xlabel("key")
axes[2].set_xlabel("acousticness")
plt.show()

"""**Step-1: Multiple Linear Regression**"""

class MultipleLinearRegression:
    def __init__(self):
        # Coefficients of the linear regression model
        self.intercept = None  # Intercept
        self.coefficients = None  # Coefficients for independent variables

        # Mean values of independent and dependent variables
        self.x_means = None  # Mean values of independent variables
        self.y_mean = None  # Mean value of dependent variable

        # Residuals (errors) of the model
        self.residuals = None

        # Sum of squared errors and total sum of squares
        self.sse = None  # Sum of squared errors
        self.sst = None  # Total sum of squares

        # R-squared and adjusted R-squared values
        self.r_squared = None
        self.r_squared_adj = None

        # Confidence intervals for coefficients and sigma
        self.confidence_intervals = None  # Confidence intervals for coefficients
        self.sigma_estimate = None  # Estimate of sigma
        self.confidence_interval_sigma = None  # Confidence interval for sigma

    def fit(self, X, y):
        n = len(y)
        p = X.shape[1]  # Number of independent variables
        self.x_means = np.mean(X, axis=0)
        self.y_mean = np.mean(y)

        X_centered = X
        self.X = X
        self.y = y

        # Compute coefficients using normal equation
        XTX_inv = np.linalg.inv(np.dot(X_centered.T, X_centered))
        beta = np.dot(np.dot(XTX_inv, X_centered.T), y)
        # print(beta.shape)
        self.intercept = self.y_mean - np.dot(self.x_means, beta)
        self.coefficients = beta

        # Calculate residuals
        y_pred = np.dot(X, beta) + self.intercept
        self.residuals = y - y_pred

        # Compute sum of squared errors and total sum of squares
        self.sse = np.sum(self.residuals ** 2)
        self.sst = np.sum((y - self.y_mean) ** 2)

        # Compute R-squared and adjusted R-squared
        self.r_squared = 1 - (self.sse / self.sst)
        self.r_squared_adj = 1 - ((1 - self.r_squared) * (n - 1) / (n - p - 1))

        # Calculate standard error of the residuals
        self.sigma_estimate = math.sqrt(self.sse / (n - p - 1))

        # Calculate confidence intervals for coefficients
        beta_std_errors = np.sqrt(np.diagonal(self.sigma_estimate**2 * XTX_inv))
        t_critical = stats.t.ppf(1 - 0.025, df=n - p - 1)  # for 95% confidence interval
        confidence_intervals = [(beta[i] - t_critical * beta_std_errors[i],
                                 beta[i] + t_critical * beta_std_errors[i])
                                 for i in range(len(beta))]
        self.confidence_intervals = confidence_intervals

        # Calculate confidence interval for sigma
        self.confidence_interval_sigma = (self.sigma_estimate * math.sqrt(stats.chi2.ppf(0.025, df=n - p - 1)),
                                          self.sigma_estimate * math.sqrt(stats.chi2.ppf(0.975, df=n - p - 1)))

    def significance_test(self, alpha=0.05):
        n = len(self.residuals)
        p = len(self.coefficients)
        df = n - p - 1
        X = self.X
        y = self.y
        # Calculate t-statistics for coefficients
        a1 = np.linalg.inv(np.dot(X.T, X))
        a2 = self.coefficients
        t_stats = self.coefficients / (self.sigma_estimate * np.sqrt(np.diagonal(np.linalg.inv(np.dot(X.T, X)))))

        # Calculate p-values
        p_values = 2 * (1 - stats.t.cdf(abs(t_stats), df))

        # Determine significance
        significant_coeffs = [p_value < alpha for p_value in p_values]

        return {'significant_coeffs': significant_coeffs}

    def anova_test(self, alpha=0.05):
        dof_regression = len(self.coefficients)
        dof_residuals = len(self.residuals) - len(self.coefficients) - 1
        sse = self.sse
        ssr = self.sst - self.sse

        # Compute mean square regression and mean square residuals
        msr = ssr / dof_regression
        mse = sse / dof_residuals

        # Compute F-statistic
        f_statistic = msr / mse

        # Compute p-value
        p_value = stats.f.sf(f_statistic, dof_regression, dof_residuals)

        # Null hypothesis: All regression coefficients are zero
        # Alternative hypothesis: At least one regression coefficient is non-zero
        if p_value < alpha:
            conclusion = "Reject the null hypothesis. At least one regression coefficient is non-zero."
        else:
            conclusion = "Fail to reject the null hypothesis. There is insufficient evidence to conclude that any regression coefficient is non-zero."

        return {
            'f_statistic': f_statistic,
            'p_value': p_value,
            'conclusion': conclusion
        }

    def plot_actual_vs_predicted(self, X_test, y_test):
        # Predict using the fitted model
        y_pred = np.dot(X_test, self.coefficients) + self.intercept

        # Plot actual vs predicted
        plt.figure(figsize=(8, 6))
        plt.plot(range(len(y_pred)), y_test, color='gray', label='Actual')
        plt.plot(range(len(y_pred)), y_pred, color='orange', label='Predicted')
        plt.title('Actual vs Predicted')
        plt.xlabel('Index')
        plt.ylabel('Value')
        plt.legend()
        plt.show()

    def get_summary(self):
        return {
            'intercept': self.intercept,
            'coefficients': self.coefficients,
            'r_squared': self.r_squared,
            'r_squared_adj': self.r_squared_adj,
            'sse': self.sse,
            'sst': self.sst,
            'confidence_intervals': self.confidence_intervals,
            'sigma_estimate': self.sigma_estimate,
            'confidence_interval_sigma': self.confidence_interval_sigma
        }

"""Train-Test Split of the Cleaned Data"""

df = pd.read_csv("cleaned_data.csv")

numerical_features = df.select_dtypes(include=["int64", "float64"])
numerical_features.fillna(0, inplace=True)
numerical_features.drop("popularity", axis=1, inplace=True)
y = df["popularity"]
y.fillna(0, inplace=True)

X_train, X_test, y_train, y_test = train_test_split(numerical_features, y, test_size=0.20, random_state=625)

"""Multiple Linear Regression on Train Dataset"""

mlr = MultipleLinearRegression()
mlr.fit(X = X_train, y = y_train)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Dropping Data with Popularity value of 0"""

# Drop rows where y_train is 0
X_dropped = X_train[y_train != 0]
y_dropped = y_train[y_train != 0]

"""Multiple Linear Regression on Modified Train Dataset"""

mlr = MultipleLinearRegression()
mlr.fit(X = X_dropped, y = y_dropped)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Simple Linear Regression"""

import numpy as np
import math
from scipy import stats

class SimpleLinearRegression:
    def __init__(self):
        # Coefficients of the linear regression model
        self.b0 = None  # Intercept
        self.b1 = None  # Slope

        # Mean values of independent and dependent variables
        self.x_mean = None
        self.y_mean = None

        # Residuals (errors) of the model
        self.residuals = None

        # Sum of squared errors and total sum of squares
        self.sse = None  # Sum of squared errors
        self.sst = None  # Total sum of squares

        # R-squared and adjusted R-squared values
        self.r_squared = None
        self.r_squared_adj = None

        # Confidence intervals for coefficients (b0 and b1) and sigma
        self.confidence_interval_b0 = None
        self.confidence_interval_b1 = None
        self.sigma_estimate = None
        self.confidence_interval_sigma = None

    def fit(self, x, y):
        n = len(x)
        self.x_mean = np.mean(x)
        self.y_mean = np.mean(y)

        numerator = np.sum((x - self.x_mean) * (y - self.y_mean))
        denominator = np.sum((x - self.x_mean) ** 2)

        self.b1 = numerator / denominator
        self.b0 = self.y_mean - self.b1 * self.x_mean

        self.residuals = y - (self.b0 + self.b1 * x)
        self.sse = np.sum(self.residuals ** 2)
        self.sst = np.sum((y - self.y_mean) ** 2)
        self.r_squared = 1 - (self.sse / self.sst)
        self.r_squared_adj = 1 - ((1 - self.r_squared) * (n - 1) / (n - 2))

        se_b0 = math.sqrt(self.sse / (n - 2)) * math.sqrt((1 / n) + (self.x_mean ** 2) / (np.sum((x - self.x_mean) ** 2)))
        se_b1 = math.sqrt(self.sse / (n - 2)) / math.sqrt(np.sum((x - self.x_mean) ** 2))
        t_critical = stats.t.ppf(1 - 0.025, df=n - 2) # for 95% confidence interval

        self.confidence_interval_b0 = (self.b0 - t_critical * se_b0, self.b0 + t_critical * se_b0)
        self.confidence_interval_b1 = (self.b1 - t_critical * se_b1, self.b1 + t_critical * se_b1)

        self.sigma_estimate = math.sqrt(self.sse / (n - 2))
        self.confidence_interval_sigma = (self.sigma_estimate * math.sqrt(stats.chi2.ppf(0.025, df=n - 2)),
                                          self.sigma_estimate * math.sqrt(stats.chi2.ppf(0.975, df=n - 2)))

    def significance_test(self, alpha=0.05):
        n = len(self.residuals)
        df = n - 2

        # Calculate t-statistic for b0 and b1
        t_stat_b0 = self.b0 / (math.sqrt(self.sse / (n * np.var(self.residuals))))
        t_stat_b1 = self.b1 / (math.sqrt(self.sse / (n * np.var(self.residuals))))

        # Calculate p-value
        p_value_b0 = 2 * (1 - stats.t.cdf(abs(t_stat_b0), df))
        p_value_b1 = 2 * (1 - stats.t.cdf(abs(t_stat_b1), df))

        # Determine significance
        b0_significant = p_value_b0 < alpha
        b1_significant = p_value_b1 < alpha

        return {'b0_significant': b0_significant, 'b1_significant': b1_significant}

    def plot_actual_vs_predicted(self, X_test, y_test):
        # Predict using the fitted model
        y_pred = self.b0 + self.b1 * X_test

        # Plot actual vs predicted
        plt.figure(figsize=(8, 6))
        plt.scatter(X_test, y_test, color='gray', label='Actual')  # Plot actual points
        plt.plot(X_test, y_pred, color='orange', label='Predicted')  # Plot regression line
        plt.title('Actual vs Predicted')
        plt.xlabel('X_test')
        plt.ylabel('y_test')
        plt.legend()
        plt.show()

    def get_summary(self):
        return {
            'b0': self.b0,
            'b1': self.b1,
            'r_squared': self.r_squared,
            'r_squared_adj': self.r_squared_adj,
            'sse': self.sse,
            'sst': self.sst,
            'confidence_interval_b0': self.confidence_interval_b0,
            'confidence_interval_b1': self.confidence_interval_b1,
            'sigma_estimate': self.sigma_estimate,
            'confidence_interval_sigma': self.confidence_interval_sigma
        }

slr_results = {}

for feature in X_train.columns:
    print("Feature = ",feature)
    slr = SimpleLinearRegression()
    slr.fit(X_train[feature], y_train)
    slr.plot_actual_vs_predicted(X_test[feature], y_test)
    slr_results[feature] = slr.get_summary()
    print()

for feature, summary in slr_results.items():
    print(f"Regression results for {feature}:")
    for key, value in summary.items():
        print(f"{key}: {value}")
    print()

"""Check for Multicollinearity"""

def calculate_r_squared(X, Y):
    # Convert DataFrame/Series to numpy arrays
    X_array = X.to_numpy()
    Y_array = Y.to_numpy()
    # print(X_array)

    # a = np.dot(X_array.T, X_array)
    a = np.dot(X_array.T, X_array)
    b = np.linalg.inv(a)
    c = np.dot(b,X_array.T)
    beta = np.dot(c,Y_array)

    Y_pred = np.dot(X_array, beta)
    Y_mean = np.mean(Y_array)

    SST = np.sum((Y_array - Y_mean)**2)
    SSE = np.sum((Y_array - Y_pred)**2)

    R_squared = 1 - SSE/SST

    return R_squared

def vif (input_data, i):
  # Extract the i-th feature
  X_i = input_data.iloc[:, i]

  # Extract all other features
  X_other = input_data.drop(input_data.columns[i], axis=1)

  R2 = calculate_r_squared(X_other, X_i)
  ans = 1/(1 - R2)

  return ans

# Function returns the data with reduced features. Considering the input_data in the format where a feature corresponds to a column.
# Assuming input_data consists of the first column with all values 1 (bias).
def reduced_features(X_train, threshold = 0.9):
  input_data = X_train.copy()
  input_data.insert(0, 'Bias', np.ones(len(input_data)))
  X = input_data.to_numpy()
  corr_df = input_data.iloc[:,1:].corr()
  # corr_df = input_data.corr()
  corr_matrix = corr_df.to_numpy()
  print(corr_df)

  num_features = len(input_data.columns) - 1
  removed_features = []

  for i in range(num_features):
    for j in range(i+1,num_features):
      if i in removed_features or j in removed_features:
        continue
      if corr_matrix[i][j] < threshold:
        continue
      vif_i = vif(input_data,i)
      vif_j = vif(input_data,j)
      if vif_i >= vif_j:
        removed_features.append(i)
      else:
        removed_features.append(j)

  for i in range(len(removed_features)):
    removed_features[i] += 1

  reduced_data = input_data.drop(input_data.columns[removed_features],axis=1)
  return reduced_data

print(reduced_features(X_train,0.9).info())

"""Principal Component Regression on Training Dataset"""

class PrincipalComponentRegression:
    def __init__(self, barrier=0.85):
        self.n_components = None
        self.threshold = barrier
        self.mean = None
        self.components = None
        self.beta = None
        self.eigenvalues = None
        self.eigenvectors = None
        self.mean = None
        self.maximums = None

    def fit(self, X, y):
        # Step 1: Center the data
        self.mean = np.mean(X, axis=0)
        X_centered = X - self.mean
        self.maximums = np.max(np.abs(X_centered), axis = 0)
        X_centered = X_centered / self.maximums
        # print(self.maximums)

        # Step 2: Perform PCA
        # covariance_matrix = np.cov(X_centered.T)
        eigenvalues, eigenvectors = np.linalg.eig(X_centered.T@X_centered)
        # print(eigenvalues)

        # print(eigenvectors)
        den = sum(eigenvalues)
        num_comp = 0
        num = 0

        eigenvectors = eigenvectors[np.argsort(eigenvalues)]
        eigenvalues = np.sort(eigenvalues)

        # print(eigenvectors)
        eigenvectors = np.flip(eigenvectors)
        eigenvalues = np.flip(eigenvalues)

        tot = len(eigenvalues)
        for i in range(tot):
            num_comp += 1
            num += eigenvalues[i]
            if num/den >= self.threshold:
              break

        self.n_components = num_comp
        # idx = eigenvalues.argsort()[::-1]
        self.components = eigenvectors[:self.n_components,:]
        # print(self.components)

        self.eigenvectors = eigenvectors
        self.eigenvalues = eigenvalues

        # Step 3: Project data onto principal components
        X_projected = np.dot(X_centered, self.components.T)

        # Step 4: Fit linear regression on projected data
        ones_column = np.ones((X_projected.shape[0], 1))
        X_regression = np.hstack((ones_column, X_projected))
        self.beta = np.linalg.inv(X_regression.T.dot(X_regression)).dot(X_regression.T).dot(y)

    def predict(self, X):
        # Step 1: Center the data
        X_centered = X - self.mean
        X_centered = X_centered / self.maximums
        # Step 2: Project data onto principal components
        X_projected = np.dot(X_centered, self.components.T)

        # Step 3: Predict using linear regression coefficients
        ones_column = np.ones((X_projected.shape[0], 1))
        X_regression = np.hstack((ones_column, X_projected))
        return X_regression.dot(self.beta)

    def plot_actual_vs_predicted(self, X_test, y_test):
        # Predict using the fitted model
        y_pred = self.predict(X_test)

        # Plot actual vs predicted
        plt.figure(figsize=(8, 6))
        plt.plot(range(len(y_pred)), y_test, color='gray', label='Actual')
        plt.plot(range(len(y_pred)), y_pred, color='orange', label='Predicted')
        plt.title('Actual vs Predicted')
        plt.xlabel('Index')
        plt.ylabel('Value')
        plt.legend()
        plt.show()

    def show_eigenvectors(self):
        print('Number of reduced components:\n',self.n_components)
        for i in range(len(self.eigenvalues)):
            print(f"Component {i+1}: ")
            print(f"Eigenvalue: {self.eigenvalues[i]}\nEigenvector: {self.eigenvectors[i]}")

pcr = PrincipalComponentRegression()

pcr.fit(X_train, y_train)
pcr.plot_actual_vs_predicted(X_test, y_test)

# Print coefficients
print("Intercept:", pcr.beta[0])
print("Coefficients for principal components:", pcr.beta[1:])

y_pred = pcr.predict(X_test)
SST = np.sum((y_test - np.mean(y_test))**2)
SSE = np.sum((y_test - y_pred)**2)

R_squared = 1 - SSE/SST
print('R-squared value:',R_squared)

pcr.show_eigenvectors()

"""Principal Component Regression removing the "mode" feature"""

X_train_new = X_train.drop('mode', axis=1)
X_test_new = X_test.drop('mode', axis=1)

pcr = PrincipalComponentRegression()

pcr.fit(X_train_new, y_train)
pcr.plot_actual_vs_predicted(X_test_new, y_test)

# Print coefficients
print("Intercept:", pcr.beta[0])
print("Coefficients for principal components:", pcr.beta[1:])

y_pred = pcr.predict(X_test_new)
SST = np.sum((y_test - np.mean(y_test))**2)
SSE = np.sum((y_test - y_pred)**2)

R_squared = 1 - SSE/SST
print('R-squared value:',R_squared)

pcr.show_eigenvectors()

"""Undersampling"""

def underSampling(X_train, y_train, cutoff):
  # Select popular samples where y_train > cutoff
  popular_mask = y_train.values > cutoff
  X_popular = X_train.values[popular_mask]
  y_popular = y_train.values[popular_mask]

  # Select unpopular samples where y_train <= cutoff
  unpopular_mask = y_train.values <= cutoff
  X_unpopular = X_train.values[unpopular_mask]
  y_unpopular = y_train.values[unpopular_mask]

  # Sample unpopular samples to match the size of popular samples
  num_samples = len(X_popular)
  sampled_indices = np.random.choice(len(X_unpopular), size=num_samples, replace=False)
  X_unpopular_sampled = [X_unpopular[indices] for indices in sampled_indices]
  y_unpopular_sampled = [y_unpopular[indices] for indices in sampled_indices]

  # Combine popular and sampled unpopular samples
  X_combined = np.concatenate((X_popular, X_unpopular_sampled), axis=0)
  y_combined = np.concatenate((y_popular, y_unpopular_sampled), axis=0)

  return X_combined, y_combined

"""Cutoff = 55"""

cutoff = 55
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Cutoff = 65"""

cutoff = 65
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Cutoff = 75"""

cutoff = 75
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Cutoff = 80"""

cutoff = 80
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Cutoff = 85"""

cutoff = 85
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Cutoff = 90"""

cutoff = 90
X_sample, y_sample = underSampling(X_train, y_train, cutoff)

mlr = MultipleLinearRegression()
mlr.fit(X = X_sample, y = y_sample)

# Get summary
summary = mlr.get_summary()
print("Intercept:", summary['intercept'])
print("Coefficients:", summary['coefficients'])
print("R-squared:", summary['r_squared'])
print("Adjusted R-squared:", summary['r_squared_adj'])
print("Sum of squared errors (SSE):", summary['sse'])
print("Total sum of squares (SST):", summary['sst'])
print("Confidence intervals for coefficients:")
for i, interval in enumerate(summary['confidence_intervals']):
    print(f"Coefficient {i+1}: {interval}")
print("Estimate of sigma:", summary['sigma_estimate'])
print("Confidence interval for sigma:", summary['confidence_interval_sigma'])

mlr.plot_actual_vs_predicted(X_test, y_test)

"""Detection of Outliers for the Final Model

Studentized Residuals
"""

# Define the value of q
q = 6 # Assuming you want to select the 2nd column, you can change this value as needed

# Selecting the q_th column of X_train
X_centered = X_sample[:1000, q]  # Selecting the q_th column
X_centered = X_centered.reshape(-1, 1)  # Reshape to ensure it's a 2D array
k = 1  # Number of features (since we are using only one feature)
y = y_sample[:1000]

XTX_inv = np.linalg.inv(np.dot(X_centered.T, X_centered))
H = np.matmul(np.matmul(X_centered, XTX_inv), X_centered.T)

n = len(y)
leverage = np.diag(H)

y_mean = np.mean(y)
x_mean = np.mean(X_centered)

data_pt = []
outlier = []
for i in range(n):
    tempX = np.delete(X_centered, i, axis=0)
    tempy = np.delete(y, i)

    temp_y_mean = y_mean * (n - 1)
    temp_x_mean = x_mean * (n - 1)

    temp_y_mean -= y[i]
    temp_x_mean -= X_centered[i]

    XTX_inv = np.linalg.inv(np.dot(tempX.T, tempX))
    beta = np.dot(np.dot(XTX_inv, tempX.T), tempy)
    intercept = temp_y_mean - np.dot(temp_x_mean, beta)

    y_pred = np.dot(X_centered, beta) + intercept
    residuals = y - y_pred

    dof_residuals = n - len(beta) - 1
    mse = np.sum(residuals ** 2) / dof_residuals

    t_statistic = residuals[i] / np.sqrt(mse * (1 - leverage[i]))

    #print(abs(t_statistic))
    if abs(t_statistic) > 1.05:
        outlier.append(i)
    else:
        data_pt.append(i)

# Plotting
plt.figure(figsize=(8, 6))
plt.scatter(X_train.values[:1000, q], y_train.values[:1000], c='gray', label='Full training set')
plt.scatter(X_sample[data_pt, q], y_sample[data_pt], c='blue', label='Non-Outliers')
plt.scatter(X_sample[outlier, q], y_sample[outlier], c='red', label='Outliers')
plt.xlabel('Features')
plt.ylabel('Popularity Score')
plt.title('Outlier Detection')
plt.legend()
plt.show()

"""JackKnife Method"""

import numpy as np
from scipy.stats import t
import math

def jack_knife_test(X, y, outlier_indices=None):
  num_samples = len(X)
  num_features = len(X[0])

  # print(num_samples, num_features)

  beta_hat = np.zeros_like((num_features + 1, num_samples))
  partial_preds = []
  outliers = []
  outlier_idx = []

  # create an object for Multiple Linear Regression - whole and partial

  mlr_whole = MultipleLinearRegression()

  # fitting the model on the whole data

  mlr_whole.fit(X, y)
  summary_whole = mlr_whole.get_summary()
  beta_hat_whole = summary_whole['coefficients'] # shape = (num_features, 1)
  beta_0_whole = summary_whole['intercept'] # shape = (1, 1)
  SSE = summary_whole['sse'] # sum(e[i]^2)

  # calculating the leverage statistic

  hat_matrix = X @ np.linalg.inv(X.T @ X) @ X.T
  hii_matrix = np.diag(hat_matrix)
  # print(hii_matrix)
  # perform MLR by leaving one datapoint out every time
  for i in range(num_samples):
    X_temp = np.delete(X, i, axis=0)
    y_temp = np.delete(y, i)

    # print(X_temp.shape, y_temp.shape)
    mlr_partial = MultipleLinearRegression()
    mlr_partial.fit(X_temp, y_temp)

    summary = mlr_partial.get_summary()
    beta_hat_partial = summary['coefficients'] # num_features number of coefficients
    beta_0_partial = summary['intercept'] # 1 intercept (beta_0)

    error_i_whole = y[i] - (X[i] @ beta_hat_whole + beta_0_whole) # residual from the whole model for the ith datapoint
    yi_pred = (X[i] @ beta_hat_partial + beta_0_partial)
    error_i_partial = y[i] - yi_pred # partial residual for the ith datapoint

    partial_preds.append(yi_pred)

    jack_knife_variance_estimate_statistic = (SSE - (error_i_whole**2/(1-hii_matrix[i])))/(num_samples-num_features-2)

    t_statistic = error_i_partial/(jack_knife_variance_estimate_statistic/(1-hii_matrix[i]))

    # test if the ith datapoint is an outlier or not
    p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df=num_samples - num_features - 2)) # 2-tail test for outlier detection
    #print(p_value)
    # print(error_i_whole, SSE, jack_knife_variance_estimate_statistic, t_statistic, p_value)
    if p_value < 0.95:  # Assuming significance level of 0.5
      outliers.append(X[i])
      outlier_idx.append(i)

  return outliers, outlier_idx

outliers, outlier_idx = jack_knife_test(X_sample[:1000], y_sample[:1000])

# print("List of possible outliers: ", outliers)
print("Corresponding indices: ", outlier_idx)
print("Number of outliers: ", len(outliers))

X2 = X_sample[:1000]
X_ = X2[:, 10]
y = y_sample[:1000]

X_outliers = X_[outlier_idx]
y_outliers = y[outlier_idx]

X_ = np.delete(X_, outlier_idx, axis=0)
y = np.delete(y, outlier_idx, axis=0)

#print(X_.shape, y.shape)

plt.scatter(X_, y, c='b')
plt.scatter(X_outliers, y_outliers, c='r')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Scatter Plot with Outliers')
plt.show()

"""**Step-2: Logistic Regression**"""

class LogisticRegression:
    # defining parameters such as learning rate, number ot iterations, whether to include intercept,
    # and verbose which says whether to print anything or not like, loss etc.
    def __init__(self, learning_rate=0.01, num_iterations=1000, fit_intercept=True, verbose=False):
        self.learning_rate = learning_rate
        self.num_iterations = num_iterations
        self.fit_intercept = fit_intercept
        self.verbose = verbose

    # function to define the Incercept value.
    def __b_intercept(self, X):
        # initially we set it as all 1's
        intercept = np.ones((X.shape[0], 1))
        # then we concatinate them to the value of X, we don't add we just append them at the end.
        return np.concatenate((intercept, X), axis=1)

    def __sigmoid_function(self, z):
        # this is our actual sigmoid function which predicts our yp
        return 1 / (1 + np.exp(-z))

    def __loss(self, yp, y):
        # this is the loss function which we use to minimize the error of our model
        return (-y * np.log(yp) - (1 - y) * np.log(1 - yp)).mean()

    # this is the function which trains our model.
    def fit(self, X, y):

        # as said if we want our intercept term to be added we use fit_intercept=True
        if self.fit_intercept:
            X = self.__b_intercept(X)

        # weights initialization of our Normal Vector, initially we set it to 0, then we learn it eventually
        self.W = np.zeros(X.shape[1])

        # this for loop runs for the number of iterations provided
        for i in range(self.num_iterations):

            # this is our W * Xi
            z = np.dot(X, self.W)

            # this is where we predict the values of Y based on W and Xi
            yp = self.__sigmoid_function(z)

            # this is where the gradient is calculated form the error generated by our model
            gradient = np.dot(X.T, (yp - y)) / y.size

            # this is where we update our values of W, so that we can use the new values for the next iteration
            self.W -= self.learning_rate * gradient

            # this is our new W * Xi
            z = np.dot(X, self.W)
            yp = self.__sigmoid_function(z)

            # this is where the loss is calculated
            loss = self.__loss(yp, y)

            # as mentioned above if we want to print somehting we use verbose, so if verbose=True then our loss get printed
            if(self.verbose ==True and i % 100 == 0):
                print(f'loss: {loss} \t')

    # this is where we predict the probability values based on out generated W values out of all those iterations.
    def predict_prob(self, X):
        # as said if we want our intercept term to be added we use fit_intercept=True
        if self.fit_intercept:
            X = self.__b_intercept(X)

        # this is the final prediction that is generated based on the values learned.
        return self.__sigmoid_function(np.dot(X, self.W))

    # this is where we predict the actual values 0 or 1 using round. anything less than 0.5 = 0 or more than 0.5 is 1
    def predict(self, X):
        return self.predict_prob(X).round()

    def show_weights(self, X):
        n = len(self.W)
        for i in range(n):
            if i:
                print('Coefficient ',i,' : ',X.columns[i-1],' : ',self.W[i])
            else:
                print('Coefficient ',i,' : Bias',' : ',self.W[i])

"""Importing the Dataset"""

df = pd.read_csv("SpotifyAudioFeaturesNov2018.csv")
df.drop_duplicates(subset=['track_id'], inplace=True)
df.to_csv('cleaned_data.csv', index=False)
print(df.info())

"""Standardized scaling of the features into comparable forms"""

# scaler = MinMaxScaler()
scaler = StandardScaler()

df = pd.read_csv("cleaned_data.csv")
print(df.info())

numerical_features = df.select_dtypes(include=["int64", "float64"])
numerical_features = pd.DataFrame(scaler.fit_transform(numerical_features), columns=numerical_features.columns)
numerical_features.fillna(0, inplace=True)
numerical_features.drop("popularity", axis=1, inplace=True)
y = df["popularity"]
y.fillna(0, inplace=True)

X_train, X_test, y_train, y_test_ = train_test_split(numerical_features, y, test_size=0.20, random_state=62, shuffle=True)

"""Undersampling"""

def underSampling(X_train, y_train, cutoff):
  # Select popular samples where y_train > cutoff
  popular_mask = y_train.values > cutoff
  X_popular = X_train.values[popular_mask]
  # print(len(X_popular))
  y_popular = [1 for i in range(len(X_popular))]
  # print(len(y_popular))

  # Select unpopular samples where y_train <= cutoff
  unpopular_mask = y_train.values <= cutoff
  X_unpopular = X_train.values[unpopular_mask]
  y_unpopular = y_train.values[unpopular_mask]

  # Sample unpopular samples to match the size of popular samples
  num_samples = len(X_popular)
  sampled_indices = np.random.choice(len(X_unpopular), size=num_samples, replace=False)
  X_unpopular_sampled = [X_unpopular[indices] for indices in sampled_indices]
  # print(len(X_unpopular_sampled))
  y_unpopular_sampled = [0 for indices in sampled_indices]
  # print(len(y_unpopular_sampled))

  # Combine popular and sampled unpopular samples
  X_combined = np.concatenate((X_popular, X_unpopular_sampled), axis=0)
  y_combined = np.concatenate((y_popular, y_unpopular_sampled), axis=0)

  # print(len(X_combined))
  # print(len(y_combined))

  return X_combined, y_combined

"""Functions for Confusion Matirx and ROC Curve Plots"""

def confusion_matrix(y, y_pred):
  y = np.array(y)
  y_pred = np.array(y_pred)
  tp = sum((y==1) & (y_pred==1))
  fp = sum((y==0) & (y_pred==1))
  tn = sum((y==0) & (y_pred==0))
  fn = sum((y==1) & (y_pred==0))

  confusion_matrix = np.array([[tp, fp], [fn, tn]])
  #plt.imshow(confusion_matrix, cmap='viridis', interpolation='nearest')
  #plt.colorbar()  # Add a colorbar to show scale
  #plt.show()
  return confusion_matrix

def roc(y, a, k=1000, plot = False):
  y = np.array(y)
  a = np.array(a)
  thresholds = [i/k for i in range(k+1)]
  cms = np.array([confusion_matrix(y, a>thres) for thres in thresholds])
  tpr = [i[0][0]/(i[0][0]+i[1][0]) for i in cms]
  fpr = [i[0][1]/(i[0][1]+i[1][1]) for i in cms]
  if(plot):
    plt.plot(fpr, tpr)
    plt.show()
  return auc(fpr, tpr)

def plot_roc_curve(y_true, y_pred_probs, label):
    fpr, tpr, _ = roc_curve(y_true, y_pred_probs)
    auc = roc_auc_score(y_true, y_pred_probs)
    plt.plot(fpr, tpr, label=label + ' (AUC = {:.2f})'.format(auc))
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.grid(True)

cutoffs = [40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90]
model = LogisticRegression(learning_rate=0.05, num_iterations=5000, verbose=False)
accuracy_metric = []
precision_metric = []
recall_metric = []
auc_metric = []

"""Cutoff = 45"""

cutoff = 45
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 55"""

cutoff = 55
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 65"""

cutoff = 65
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 75"""

cutoff = 75
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 80"""

cutoff = 80
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

model.show_weights(X_train)

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 85"""

cutoff = 85
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

"""Cutoff = 90"""

cutoff = 90
#print(df_train.shape)
#print(df_train[df_train["popularity"]>80].shape)
#print(y_train[y_train > cutoff].count())
X_u, y_u = underSampling(X_train, y_train, cutoff)
y_test = np.where(y_test_>=cutoff, 1, 0)

#print("CNT TRAIN: ", sum(y_u==0), sum(y_u==1))
#print("### DATASET SIZE ###", X_u.shape)
model.fit(X_u, y_u)

a = model.predict_prob(X_test)
#print(a)
y_pred = model.predict(X_test)
#print("CNT PRED: ", sum(y_pred==0), sum(y_pred==1))
#print(sum(y_test==0), sum(y_test==1))

#print("RESULTS AT CUTOFF ", cutoff)
#accuracy = sum(y_test==y_pred)/y_test.shape
#print("ACCURACY: ", accuracy[0])
#print(confusion_matrix(y_test, y_pred))
#roc(y_test, a, 20, False)

print("RESULTS AT CUTOFF ", cutoff)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
auc = roc_auc_score(y_test, a)

accuracy_metric.append(accuracy)
print("ACCURACY: ", accuracy)
precision_metric.append(precision)
print("PRECISION: ", precision)
recall_metric.append(recall)
print("RECALL: ", recall)
auc_metric.append(auc)
print("AUC: ", auc)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

plt.figure(figsize=(8, 6))
plot_roc_curve(y_u, model.predict_prob(X_u), label='Train')
plot_roc_curve(y_test, a, label='Test')
plt.show()

cutoff_values = [45,55,65,75,80,85,90]

plt.plot(cutoff_values, accuracy_metric, color = 'red', label='Accuracy')
plt.plot(cutoff_values, recall_metric, color = 'orange', label='Recall')
plt.plot(cutoff_values, auc_metric, color = 'blue', label='AUC')
plt.xlabel('Popularity Cutoffs')
plt.ylabel('Auc / Rate (Others)')
#plt.grid(axis='x')
#plt.grid(axis='y')
plt.title('Metric vs Popularity Cutoffs - Test Dataset')
plt.legend()
plt.show()